{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thedarredondo/data-science-fundamentals/blob/main/Unit6/Unit6ExercisesSF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS5B_nNY9aN-"
   },
   "source": [
    "# Unit 6 Exercises: Is my model good?\n",
    "\n",
    "#### Over and Under fitting, Model Visualization, and Model/Variable Selection Concepts\n",
    "\n",
    "These exercises are meant to get you to think about the model and variable selection process, and consider how we determine if a model is \"good\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RComfTFn_vAD"
   },
   "source": [
    "## Task1\n",
    "\n",
    "Does `elpd_loo` mean anything if we only have one model?\n",
    "\n",
    "---\n",
    "\n",
    "No, because `elpd_loo` is a metric that helps us tell the difference between two or more models, but doesn't convey information without doing such a comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnfTK1y84qL-"
   },
   "source": [
    "## Task2\n",
    "\n",
    "Describe overfitting, in the context of this course.\n",
    "\n",
    "---\n",
    "\n",
    "Overfitting is when the model is distracted by irrelevant patterns in the data. Generally, a model with more variables is more likely to have greater overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoP-6zyt5PHr"
   },
   "source": [
    "## Task3\n",
    "\n",
    "How do we mitigate overfitting?\n",
    "\n",
    "---\n",
    "\n",
    "To mitigate overfitting, we use weakly informative priors and minimize the amount of variables used in our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdQNC0Nd5r88"
   },
   "source": [
    "## Task4\n",
    "\n",
    "How do we mitigate underfitting?\n",
    "\n",
    "---\n",
    "\n",
    "We mitigate underfitting by comparing models and choosing the one with a relatively good `elpd_loo`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvlCHxDK6OJJ"
   },
   "source": [
    "## Task5\n",
    "\n",
    "Why would we want more than one predictor in a model?\n",
    "\n",
    "---\n",
    "\n",
    "We want more than one predictor when we determine that there is a more complicated relationship between the variables we are trying to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oijEFidC6coD"
   },
   "source": [
    "## Task6\n",
    "\n",
    "Can we have too many predictors? How would we now?\n",
    "\n",
    "---\n",
    "\n",
    "There is such a thing as too many predictors. We know when there are too many predictors when we detect overfitting. In general, we can use our knowledge of the variables to create a DAG and see which ones actually cause what we are trying to analyze. Also, we can use metrics like `elpd_loo` to hint at weaknesses in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRJeg7NL7HPN"
   },
   "source": [
    "## Task7\n",
    "\n",
    "What is variable selection, and how does it work?\n",
    "\n",
    "---\n",
    "\n",
    "Variable selection is the process of choosing the correct predictors for a given task. This includes determining whether multiple predictors are needed, how many are needed, and which are the best to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OntaA0WLo551"
   },
   "source": [
    "## Task8\n",
    "\n",
    "Describe the differences and similarities between the following three models: linear regression with two predictors, one of which is a categorical variable:\n",
    "\n",
    "- adding the variables in the model, as is standard.\n",
    "- using that categorical variable as a hierarchy upon the other predictor variable.\n",
    "- adding the variables, plus the categorical variable's interaction with the other variable.\n",
    "\n",
    "---\n",
    "\n",
    "In the example from the notes, I noticed the following similarities and differences.\n",
    "\n",
    "When we add just variables in the model, we don't split it into categories and we get a single graph. When we have a categorical model, Bambi chooses the same slope for the categories but varies their intercepts, specific to the given category. A hierarchy represents another relationship between variables that also allows their slopes to vary on the graphs. Both categories and hierarchies are tools we use based on our knowledge of the relationships between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAalFZA-sNtB"
   },
   "source": [
    "## Task9\n",
    "\n",
    "How do we visualize multiple linear regression models? Can we visualize the entire model, all at once\n",
    "\n",
    "---\n",
    "\n",
    "We visualize multiple linear regression models by choosing two variables to plot on the x and y axis, and possibly a category for which we draw multiple lines. We typically cannot visualize the entire model all at once, and need multiple plots to understand what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xx4j9ttl4N3"
   },
   "source": [
    "## Task10\n",
    "\n",
    "Compare the following linear models that all use the basketball data to predict field goal percentage:\n",
    "\n",
    "1. predictors free throw percentage and position (with position as a categorical predictor)\n",
    "2. predictors free throw percentage and position (with position as a hierarchy)\n",
    "3. predictors free throw percentage and position (with position interacting with frew throw percentage)\n",
    "4. predictors free throw percentage, position, 3 point attempts, and interactions between all three predictors\n",
    "5. predictors free throw percentage, position, 3 point attempts, with an interaction between 3 point attempts and postion.\n",
    "\n",
    "using ```az.compare()``` and ```az.plot_compare()```, or an equivalent method using LOO (elpd_loo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSAypAHJmoJy"
   },
   "source": [
    "You may use the following two code blocks to load and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bambi as bmb\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kfVxvltJlOa2"
   },
   "outputs": [],
   "source": [
    "#have to drop incomplete rows, so that bambi will run\n",
    "bb = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/thedarredondo/data-science-fundamentals/refs/heads/main/Data/basketball2324.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oevLDINKridn"
   },
   "outputs": [],
   "source": [
    "#only look at players who played more than 600 minutes\n",
    "#which is 20 min per game, for 30 games\n",
    "bb = bb.query('MP > 600')\n",
    "#remove players who never missed a free throw\n",
    "bb = bb.query('`FT%` != 1.0')\n",
    "#filter out the combo positions. This will make it easier to read the graphs\n",
    "bb = bb.query(\"Pos in ['C','PF','SF','SG','PG']\")\n",
    "#gets rid of the annoying '%' sign\n",
    "bb.rename(columns={\"FT%\":\"FTp\",\"FG%\":\"FGp\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, Intercept, FTp, Pos]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4766c527dfb4efd83311fb246a17d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "model1 = bmb.Model(\"FGp ~ FTp + Pos\", data=bb)\n",
    "idata_model1 = model1.fit(idata_kwargs={\"log_likelihood\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, Intercept, 1|Pos_sigma, 1|Pos_offset, FTp|Pos_sigma, FTp|Pos_offset]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8e71e9bb534103831caf6d56d487e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 26 seconds.\n",
      "There were 137 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "model2 = bmb.Model(\"FGp ~ (FTp | Pos)\", data=bb)\n",
    "idata_model2 = model2.fit(idata_kwargs={\"log_likelihood\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, Intercept, FTp, Pos, FTp:Pos]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1739168003e47bd97ea1dd3918dacc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 14 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "model3 = bmb.Model(\"FGp ~ FTp + Pos + FTp:Pos\", data=bb)\n",
    "idata_model3 = model3.fit(idata_kwargs={\"log_likelihood\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, Intercept, FTp, Pos, 3PA, FTp:Pos:3PA]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd829331bda4011b64d8d49f371fc48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 11 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "model4 = bmb.Model(\"FGp ~ FTp + Pos + `3PA` + FTp:Pos:`3PA`\", data=bb)\n",
    "idata_model4 = model4.fit(idata_kwargs={\"log_likelihood\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, Intercept, FTp, Pos, 3PA, 3PA:Pos]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb55683adec4d29b7ec31b3ee74c021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 7 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Model 5\n",
    "model5 = bmb.Model(\"FGp ~ FTp + Pos + `3PA` + `3PA`:Pos\", data=bb)\n",
    "idata_model5 = model5.fit(idata_kwargs={\"log_likelihood\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 4</th>\n",
       "      <td>0</td>\n",
       "      <td>531.554708</td>\n",
       "      <td>13.833942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.866742e-01</td>\n",
       "      <td>15.105571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 5</th>\n",
       "      <td>1</td>\n",
       "      <td>529.836221</td>\n",
       "      <td>12.720547</td>\n",
       "      <td>1.718486</td>\n",
       "      <td>3.133258e-01</td>\n",
       "      <td>15.877077</td>\n",
       "      <td>3.127500</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>2</td>\n",
       "      <td>509.396937</td>\n",
       "      <td>13.758973</td>\n",
       "      <td>22.157771</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>16.701151</td>\n",
       "      <td>6.913375</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>3</td>\n",
       "      <td>508.473508</td>\n",
       "      <td>13.650741</td>\n",
       "      <td>23.081199</td>\n",
       "      <td>2.221671e-15</td>\n",
       "      <td>16.921504</td>\n",
       "      <td>6.870815</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>4</td>\n",
       "      <td>507.390955</td>\n",
       "      <td>8.224211</td>\n",
       "      <td>24.163752</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>16.062300</td>\n",
       "      <td>6.992583</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rank    elpd_loo      p_loo  elpd_diff        weight         se  \\\n",
       "Model 4     0  531.554708  13.833942   0.000000  6.866742e-01  15.105571   \n",
       "Model 5     1  529.836221  12.720547   1.718486  3.133258e-01  15.877077   \n",
       "Model 3     2  509.396937  13.758973  22.157771  0.000000e+00  16.701151   \n",
       "Model 2     3  508.473508  13.650741  23.081199  2.221671e-15  16.921504   \n",
       "Model 1     4  507.390955   8.224211  24.163752  0.000000e+00  16.062300   \n",
       "\n",
       "              dse  warning scale  \n",
       "Model 4  0.000000    False   log  \n",
       "Model 5  3.127500    False   log  \n",
       "Model 3  6.913375    False   log  \n",
       "Model 2  6.870815    False   log  \n",
       "Model 1  6.992583    False   log  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({\"Model 1\": idata_model1,\n",
    "            \"Model 2\": idata_model2,\n",
    "            \"Model 3\": idata_model3,\n",
    "            \"Model 4\": idata_model4,\n",
    "            \"Model 5\": idata_model5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXReX4nNjKvl"
   },
   "source": [
    "## Task11\n",
    "\n",
    "Which model is \"better\" according to this metric?\n",
    "\n",
    "Why do you think that is?\n",
    "\n",
    "---\n",
    "\n",
    "According to this metric, model 4 is the best. It's probably because the model fits the data very closely due to the relationship between all predictors. However, this might be overfitting, in wich case model 5 might even be better since the `elpd_loo`s are pretty close."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMrqL0D5yck5wIPN8bOF2Rm",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
