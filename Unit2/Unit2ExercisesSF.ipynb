{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "editable": true,
    "id": "view-in-github",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thedarredondo/data-science-fundamentals/blob/main/Unit2/Unit2ExercisesSF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GANUQSIhV2t"
   },
   "source": [
    "# Unit 2 Exercises: Bayesian Building Blocks\n",
    "\n",
    "This first set of exercises focuses on conceptual understanding of the three parts of bayesian statistics we'll manipulate the most: the prior, likelihood, and posterior.\n",
    "\n",
    "These vocabulary words will help us categorize and explain all statistical models, even models that don't fit inside the standard bayesian framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HnMLojUPtOR"
   },
   "source": [
    "**Task1**:\n",
    "\n",
    "Why do we make guesses? In other words, what is the benefit of trying to predict something we are uncertain about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDaA1AeLU5dU"
   },
   "source": [
    "Making guesses gives valuable information, even if we don't have complete certainty of a result. Probability distributions show the inherent uncertainty of a result, but at the same time allow us to use different heuristics (such as mean, median, mode) to come up with a generalized result. At the end of the day, these ways allow us to come up with a good idea of what the future may look like, which is a lot better than nothing at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMU4F4ZGQqb9"
   },
   "source": [
    "**Task2**:\n",
    "\n",
    "Is is it possible to make a guess/prediction without making an assumption?\n",
    "\n",
    "If yes, then give an example of such a guess, and state whenever that guess would be useful or not.\n",
    "\n",
    "If no, then briefly justify why we need assumptions to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuBQVSQ0U-cD"
   },
   "source": [
    "No, we need assumptions to make predictions. Predictions imply a level of uncertainty. In order to deal with this, we have to make assumptions about what models and parameters to use in order to represent a future scenario. Whether we include a factor or don't, we are making an assumption about the factor's importance in our predictive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iIogaaJQEfl"
   },
   "source": [
    "**Task3**:\n",
    "\n",
    "Should we use all the available information we have to make a guess/prediction? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8zljy-5QXSd"
   },
   "source": [
    "I would say yes. While there is always uncertainty, real-life scenarios have a number of known inputs that can help make predictions more accurate. We can look at just past free throws, but that would leave out important factors such as morale, injuries, whether it's a home game, etc. that might affect the result of the free throw. Ultimately, we currently have no way to create a 1:1 model of reality, nor do our computing resources allow for it. Thus, we must choose the most important and quantifiable factors within the constraints of our data collection/computing resources to make a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYwtd8lPRFbj"
   },
   "source": [
    "**Task4**:\n",
    "\n",
    "What is a prior? How are priors related to\n",
    "- context?\n",
    "- assumptions?\n",
    "- predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6vRRh3wVE5v"
   },
   "source": [
    "A prior is a probability distribution made before taking account of some data. Choosing a prior is an important assumption that sets up our prediction. We need to decide what we want for our prior, whether it be a distribution based on past data, an artificially-made distribution based on our own knowledge of a topic, or even the so-called \"uninformative\" prior (like our assumption that all possible percentages are equally likely). We rely on the context of the situation we are trying to analyze in order to make assumptions about what type of distribution would best fit the predictions we are trying to make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6NnzoV_RWo6"
   },
   "source": [
    "**Task5**:\n",
    "\n",
    "What is a likelihood? How are likelihoods related to:\n",
    "\n",
    "- context?\n",
    "- assumptions?\n",
    "- predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK5s3vZpVGLc"
   },
   "source": [
    "A likelihood is a function that calculates the probability of a certain event occuring. Its power comes from the fact that it can be provided with context from a prior. A prior gives us an idea of the distribution that the data set will follow. This distribution is used by the likelihood to make calculations. At this part of the process, we make the assumption that our prior is an accurate-enough representation of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYSYtG_2Rowf"
   },
   "source": [
    "**Task6**:\n",
    "\n",
    "What is a posterior? How are posteriors related to:\n",
    "\n",
    "- context?\n",
    "- assumptions?\n",
    "- predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T04x1VteVHH1"
   },
   "source": [
    "A posterior is a probability made by combining a prior and likelihood. It is essentially a model of our uncertainty that we can use to make predictions. The context for the posterior comes from the prior and likelihood. We make assumptions about the compatibility about the likelihood and posterior used to make the prior. The prior can be used as a tool to make predictions based on everything we know about a certain topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMAm4LqBXYxG"
   },
   "source": [
    "**Task7**:\n",
    "\n",
    "Why would anyone want to define a prior and a likelihood in order to make a prediction? In other words, what's the point of using a likelihood and a prior to form a posterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rag62h9DVIDN"
   },
   "source": [
    "The prior gives us an estimate of what the probability distribution representing the posterior would look like. The likelihood is used to refine this model based on collected data. The combination allows the posterior to be a powerful predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNrO2k34SGoF"
   },
   "source": [
    "## Bayes' Rule Math\n",
    "\n",
    "The following exrcises will be graded for completion, with no accuracy component. That said, correct answers below will replace mistakes in tasks 1-7.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7KMRJa_TmdF"
   },
   "source": [
    "### Mathematical Framing\n",
    "\n",
    "In this series of exercises, we'll calculate a probability using the full version of Bayes' Rule.\n",
    "\n",
    "The version seen in the notes, $p(θ|y) ∝ p(y|θ)p(θ)$, ignores the normalizing constant found in the full equation: $p(θ|y) = \\frac{p(y|θ)p(θ)}{p(y)}$.\n",
    "\n",
    "As stated in the notes, in practical applications we don't need to worry too much about $p(y)$, AKA the marginal likelihood, AKA the prior predictive density, AKA the normalizing constant. And when we do, we'll approximate like we do everything else.\n",
    "\n",
    "But we these exercises are closer to theoretical abstraction, rather than practicality.\n",
    "\n",
    "So why do them?\n",
    "\n",
    "These exercises will hopefully help you gain additional inuition for probability, and how it behaves.\n",
    "\n",
    "As you work through the exercises, consider $p(y)$, the  prior predictive density, and why using it to divide $p(y|θ)p(θ)$ gurantees we get a probability.\n",
    "\n",
    "Additonaly, wonder about:\n",
    "- the likelihood $p(y|θ)$\n",
    "- the prior $p(θ)$,\n",
    "- why multiplying the likelihood and piror (almost) gives us the posterior $p(θ|y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab7E9RIuj2OX"
   },
   "source": [
    "### Problem Setting\n",
    "\n",
    "Imagine we have a bag of red and white marbles, identical in every other way. Let's assume there are 4 total marbles, we can't see inside the bag, and when we grab a ball from the bag, we replace it and shake the bag to scramble the balls.\n",
    "\n",
    "Additionally:\n",
    "\n",
    "- we draw three balls in this order: red-white-red. Call these the data, $y$. Remember, we replaced the ball and shook the bag between each draw.\n",
    "- we are interested in finding the true proportion of red balls in the bag, called $θ$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmHTGWQQHuAD"
   },
   "source": [
    "**Task8**:\n",
    "\n",
    "Write out all the possible color compositions of the marbless in the bag, before we observed our data $y$.\n",
    "\n",
    "Let each of these possible color compositions be a possible $θ$, or true proportion of red marbles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkPylHwCVK72"
   },
   "source": [
    "- red, red, red, red\n",
    "- red, red, red, white\n",
    "- red, red, white, white\n",
    "- red, white, white, white\n",
    "- white, white, white white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TELvcnVH8N2"
   },
   "source": [
    "**Task9**:\n",
    "\n",
    "Which color compositions are possible after seeing the data $y$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7q6nUOdNMN9Z"
   },
   "source": [
    "- red, red, red, white\n",
    "- red, red, white, white\n",
    "- red, white, white, white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIjecZm7OVcy"
   },
   "source": [
    "**Task10**:\n",
    "\n",
    "How many ways can you select red-white-red, assuming that there are 2 red marbles and 2 white marbles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2vDjMVIXtWR"
   },
   "source": [
    "In the bag: red1, red2, white1, white2\n",
    "\n",
    "1. red1, white1, red1\n",
    "2. red1, white1, red2\n",
    "3. red1, white2, red1\n",
    "4. red1, white2, red2\n",
    "5. red2, white1, red1\n",
    "6. red2, white1, red2\n",
    "7. red2, white2, red1\n",
    "8. red2, white2, red2\n",
    "\n",
    "8 ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs7tx0pXhUZy"
   },
   "source": [
    "**Task11**:\n",
    "\n",
    "How many different ways can you select three balls so that order matters, given that there are 2 red marbles and 2 white marbles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69ScN4NYh6ks"
   },
   "source": [
    "In the bag: 4 unique marbles\n",
    "\n",
    "- Ways to select 1 ball: 4\n",
    "- Ways to select 3 balls so that order matters: $4 \\times 4 \\times 4 = 64$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k87Z69qUg9KV"
   },
   "source": [
    "**Task12**:\n",
    "\n",
    "What's the probablity you select red-white-red, given that there are 2 red marbles and 2 white marbles?\n",
    "\n",
    "Stated differently, Find the likelihood $p(y|θ)$, where $θ=RRWW$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5bdqu1nri3Y"
   },
   "source": [
    "Ways to select RWR: 8\n",
    "Total ways: 64\n",
    "\n",
    "Result: $8 / 64$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6e9WP49sZJh"
   },
   "source": [
    "**Task13**:\n",
    "\n",
    "Find:\n",
    "\n",
    "- $p(y|WWWW)$\n",
    "- $p(y|RWWW)$\n",
    "- $p(y|RRWW)$\n",
    "- $p(y|RRRW)$\n",
    "- $p(y|RRRR)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbSC4dj_tf4Y"
   },
   "source": [
    "- $p(y|WWWW) = 0$ (impossible with all white)\n",
    "- $p(y|RWWW) = 3 / 64$\n",
    "- $p(y|RRWW) = 8 / 64$\n",
    "- $p(y|RRRW) = 9 / 64$\n",
    "- $p(y|RRRR) = 0$ (impossible with all red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxSVk_Sjv8Gk"
   },
   "source": [
    "**Task14**:\n",
    "\n",
    "Find the probablity of getting red-white-red, $p(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3PVjOk5wDZT"
   },
   "source": [
    "$p(y) = 0 + \\frac{3}{64} + \\frac{8}{64} + \\frac{9}{64} + 0 = \\frac{20}{64}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYoWtEwxyNB-"
   },
   "source": [
    "**Task15**:\n",
    "\n",
    "Given that all color compositions are equally likely, and after observing  a draw of red-white-red, find the probability that there are two red marbles and two white marbles in the bag.\n",
    "\n",
    "In other words, find $p(θ|y)$, where $θ=RRWW$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxX-o3Uuy9eR"
   },
   "source": [
    "20 ways to get RWR\n",
    "8 ways to get it with RRWW\n",
    "\n",
    "Therefore, for $\\theta = RRWW$, $p(\\theta | y) = \\frac{8}{20}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgMdbaKW1o39"
   },
   "source": [
    "**Task16**:\n",
    "\n",
    "Story time: The marble factory produces bags of four marbles. They want to make red marbles rare, so that people will get excited about them.  Therefore, for each 1 bag containing four red, they made 2 that contain three red, 3 that contain two red, 4 that contain one red, and 5 that contain zero red.\n",
    "\n",
    "With this new prior information, find $p(θ|y)$, where $θ=RRWW$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMMrUAIs3Dsi"
   },
   "source": [
    "Of all bags:\n",
    "\n",
    "- 1 in 15 bags are RRRR\n",
    "- 2 in 15 bags are RRRW\n",
    "- 3 in 15 bags are RRWW\n",
    "- 4 in 15 bags are RWWW\n",
    "- 5 in 15 bags are WWWW\n",
    "\n",
    "$$\\frac{3 \\times 8}{1 \\times 0 + 2 \\times 9 + 3 \\times 8 + 4 \\times 3 + 5 \\times 0} = 4/9$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABn_s24K4K0H"
   },
   "source": [
    "**Task17**:\n",
    "\n",
    "Write down similarities and differences between this marble example, and the Victor Wembanyama FT example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "CAmT3Bd34fhc",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The examples are similar in that both situations represent true or false events. In the case of basketball, it was whether he got a free throw. In the case of marbles, it was whether a certain combination of marbles would be drawn.\n",
    "\n",
    "There were important differences. First of all, Wembanayama's free throws were not truly random, but affected by quantifiable factors, even if we didn't analyze them. Additionally, one free throw could have affected the next, but we ignored this possiblity. Drawing marbles is straightforward and random.\n",
    "\n",
    "Furthermore, we took different processes in analyzing the data. In the free throw example, we were given a prior and likelihood, which we used to calculate a posterior. In the case of the marbles, we started with an observation, and then used analytical methods to determine the likelihood of a certain situation occurring."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMqqNkZHfrj02AHqNPqny39",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
